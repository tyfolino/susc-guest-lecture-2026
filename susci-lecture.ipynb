{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340f975a-fb5f-4853-ad49-f1a002a7ac21",
   "metadata": {},
   "source": [
    "# Lecture 6: NetCDF, OPeNDAP, Xarray, Cartopy, & PyGMT\n",
    "Guest Lecture by Ty Janoski, Ph.D.\n",
    "\n",
    "February 24th, 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gh8hko3ctdf",
   "metadata": {},
   "source": [
    "## Today's Workflow\n",
    "\n",
    "This lecture covers five tools that work together in a typical geospatial climate data workflow:\n",
    "\n",
    "```\n",
    "Climate Data\n",
    "    │\n",
    "    ▼\n",
    "NetCDF (.nc files) ── the file format that stores labeled, multi-dimensional arrays\n",
    "    │\n",
    "    ▼\n",
    "OPeNDAP ─────────── a protocol for accessing NetCDF data remotely (no download needed)\n",
    "    │\n",
    "    ▼\n",
    "Xarray ──────────── a Python library for reading, manipulating, and slicing that data\n",
    "    │\n",
    "    ▼\n",
    "Cartopy / PyGMT ─── Python libraries for visualizing the data on geographic maps\n",
    "```\n",
    "\n",
    "By the end of this lecture, you'll be able to pull climate model output from a remote server and produce publication-quality maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147833e9-6d77-4062-94ab-2ecec92fe2ee",
   "metadata": {},
   "source": [
    "## NetCDF: Network Common Data Form"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d7eefbc-ad7c-4f8b-995b-5b7d62552058",
   "metadata": {},
   "source": [
    "Sources for this section: \n",
    "- [CEDA Archive NetCDF Page](https://help.ceda.ac.uk/article/106-netcdf).\n",
    "- [UCAR NetCDF Users Guide](https://docs.unidata.ucar.edu/nug/current/netcdf_introduction.html)\n",
    "- [Data Carpentry for Oceanographers Introduction to netCDF](https://adyork.github.io/python-oceanography-lesson/17-Intro-NetCDF/index.html)\n",
    "\n",
    "### Introduction to NetCDF\n",
    "\n",
    "NetCDF is an **interface for accessing and manipulating labeled data arrays**. Although it is not *strictly* a file format, it can be thought of as such. NetCDF files will end with \".nc\". Most climate, atmospheric, and ocean model data is distributed as netCDF files.\n",
    "\n",
    "NetCDF has some advantages:\n",
    "- Files are *self-describing*, i.e., they contain information about the data structure and attributes *in the files themselves* (called metadata)\n",
    "- Platform independent and supported by many tools for data access\n",
    "- Stored in binary format, which is storage-efficient\n",
    "  \n",
    "### NetCDF Structure\n",
    "\n",
    "Data is stored as **labeled arrays** where each array has the same data type.\n",
    "\n",
    "NetCDF files will typically have **variables**, **dimensions/coordinates**, and **attributes**.\n",
    "\n",
    "![Xarray Dataset/NetCDF Diagram](https://howto.eurec4a.eu/_images/dataset-diagram.png)\n",
    "\n",
    "#### Variables:\n",
    "\n",
    "Variables are arrays of the same type that store the actual data (i.e., temperature, pressure, salinity). They will have a name, data type, and shape, where the shape corresponds to the dimensions describing the data.\n",
    "\n",
    "![netCDF diagram](https://www.esri.com/arcgis-blog/wp-content/uploads/2012/04/netCDF_SliceDiagram.png)\n",
    "Source: [esri ArcGIS blog](https://www.esri.com/arcgis-blog/products/product/analytics/including-netcdf-dimension-values-in-the-name-of-an-output-layer-or-table/)\n",
    "\n",
    "#### Dimensions:\n",
    "Dimensions provide the shape information for data variables and may represent an actual physical dimension like latitude, longitude, height, or time. They have a name and size.\n",
    "\n",
    "Coordinate arrays provide data that gives meaning to the dimensions. For example, there might be a \"time\" dimension of size 365 and a corresponding \"time\" coordinate array that holds the calendar date for each time.\n",
    "\n",
    "#### Attributes:\n",
    "\n",
    "Attributes *describe* the data such as providing information about map projections, units, or other helpful data properties.\n",
    "\n",
    "### Accessing netCDF data\n",
    "\n",
    "We will use OPeNDAP to access climate model output and the Python library Xarray to interface with it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49ad56c0-cbd5-4edd-8520-96ec1ffef1b6",
   "metadata": {},
   "source": [
    "## OPeNDAP: Open-Source Project for a Network Data Access Protocol\n",
    "\n",
    "Sources for this section: [OPeNDAP Tutorial](https://opendap.github.io/documentation/QuickStart.html)\n",
    "\n",
    "![image.png](https://www.opendap.org/wp-content/uploads/2024/01/Logo-red-2.png)\n",
    "\n",
    "OPeNDAP is **a data access protocol that lets you access data remotely**. This means that you do not have to download the data on your machine, which is very helpful for climate data that can be hundreds of TBs. Your computer can likely hold 1 TB.\n",
    "\n",
    "Note that although we do not have to download the data, depending on what you are doing, you will still have to inevitably *load the data into your memory*. You have to be cognizant of your RAM (typically less than 32 GB on your personal machine) when working with climate data. Using tools like [dask](https://www.dask.org) can help you get around this, as well as being a smart programmer, but those are beyond the scope of this lecture.\n",
    "\n",
    "Columbia has a server full of climate model output that is set up so that you can access it with OPeNDAP. All we need is a link and a library, like Xarray, to get started."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "268eef4f-44b7-42f7-a420-f51696d54ac6",
   "metadata": {},
   "source": [
    "## Xarray: labelled multi-dimensional arrays\n",
    "\n",
    "Sources for this section:\n",
    "- [Xarray in 45 minutes](https://tutorial.xarray.dev/overview/xarray-in-45-min.html)\n",
    "- [Ryan Abernathey's Xarray Tutorial](https://rabernat.github.io/research_computing/xarray.html)\n",
    "- [Project Pythia Introduction to Xarray Cookbook](https://foundations.projectpythia.org/core/xarray/xarray-intro.html)\n",
    "\n",
    "<img src=\"https://repository-images.githubusercontent.com/13221727/f43c8900-75c0-11ea-9e1b-66b0af0689e0\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "### Introduction & Gathering Data\n",
    "\n",
    "We will be playing around with model output generated during the *Climate Model Intercomparison Project Phase 6 (CMIP6)*. In this experiment, modeling groups worldwide produced a standard set of simulations with their models.\n",
    "\n",
    "The first step is to simply import Xarray. We will import NumPy and Matplotlib while we are at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c14e26-695f-4389-ad1e-e98f3bcfe5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# These are some \"magic\" statements to make displaying plots a bit smoother\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e031e-3564-480d-96c1-d9d0c24ffcdf",
   "metadata": {},
   "source": [
    "Now we are going to \"read in\" one climate model simulation containing the 2 meter air temperature from one experiment. The model name is CESM (Community Earth System Model) and the experiment is \"SSP585,\" meaning that this climate model simulation is forced according to the SSP585 (high fossil-fueled development) emissions scenario.\n",
    "\n",
    "Notice how easy it is to use Xarray's `open_dataset()` function to access the data. All we need is the OPeNDAP link!\n",
    "\n",
    "**Slight complication**: The data on Columbia’s server uses an invalid calendar format, which causes issues when Xarray tries to open it. I am going to provide a `fix_calendar()` function below. Do not worry about the specifics of what it is doing, but realize that in most cases outside of Columbia, you will not have to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8c28f-5d68-4885-81bd-cc56ea4a9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columbia's OPeNDAP server stores time with an unofficial \"360\" calendar label.\n",
    "# Xarray requires the CF-compliant label \"360_day\". This function patches it.\n",
    "# (You won't need this for most NetCDF files — it's specific to this server.)\n",
    "# Note: the ': xr.Dataset' and '-> xr.Dataset' are optional type hints —\n",
    "# they tell Python what types the function expects and returns. Don't worry about them\n",
    "#  for now.\n",
    "def fix_calendar(ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Overwrite the dataset's '360' calendar to a '360_day' to be CF-compliant.\n",
    "\n",
    "    Input:\n",
    "    ds: the Xarray Dataset whose calendar to fix. Time axis is called 'T'.\n",
    "\n",
    "    Output:\n",
    "    fixed: Xarray Dataset with fixed calendar\n",
    "    \"\"\"\n",
    "    ds.T.attrs[\"calendar\"] = \"360_day\"\n",
    "    return xr.decode_cf(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59867a96-7f8d-461c-a2cf-5b040c2e001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for Columbia's OPeNDAP server. Reading the path left to right:\n",
    "#   CMIP6i   → CMIP6 data archive\n",
    "#   ssp585   → SSP5-8.5 \"worst case\" emissions scenario\n",
    "#   Amon     → monthly atmospheric output\n",
    "#   tas      → surface air temperature variable\n",
    "#   CESM2    → Community Earth System Model v2\n",
    "#   r1i1p1f1 → first ensemble member (one of many possible model runs)\n",
    "url = (\n",
    "    \"http://mary.ldeo.columbia.edu:81/CMIP6i/.byScenario/.ssp585/.Amon/\"\n",
    "    + \".tas/.CESM2/.gn/.r1i1p1f1/.tas/dods\"\n",
    ")\n",
    "LOCAL_FILE = \"tas_CESM2_ssp585_2015-2025.nc\"\n",
    "\n",
    "try:\n",
    "    ds = xr.open_dataset(url, decode_times=False)  # decode_times=False:\n",
    "    # let fix_calendar handle it\n",
    "    ds = fix_calendar(ds)\n",
    "    print(\"Loaded from OPeNDAP (full dataset: 2015–2100).\")\n",
    "except Exception as e:\n",
    "    # If the server is unavailable, load a pre-downloaded local copy\n",
    "    print(f\"OPeNDAP unavailable ({e})\\nLoading local fallback (2015–2025).\")\n",
    "    ds = xr.open_dataset(LOCAL_FILE)\n",
    "\n",
    "# Look at ds\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6660a0-e0f4-48ac-b0a8-d10a4263ce1f",
   "metadata": {},
   "source": [
    "Xarray's `open_dataset()` function has several arguments, which refer to optional keyword arguments (also called parameters) in programming. Here are a few to know:\n",
    "- `engine`: specifies the underlying backend to interpret the files. Xarray is \"guessing\" to use `netcdf4` for the file we opened, but depending on the data, you can alternatively use `h5netcdf` or `zarr` among others\n",
    "- `decode_cf` and `decode_times`: set these to `False` if Xarray encounters issues interpreting the calendar or metadata in the file.\n",
    "- `drop_variables`: can give a string or list of strings to specify variables you do not want to read in from the netCDF file.\n",
    "- `open_mfdataset()`: use instead of `open_dataset()` when you have **multiple files** to open at once (e.g., one file per year). Xarray concatenates them automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cd5f3-3167-41b2-b8a4-2ee82634f976",
   "metadata": {},
   "source": [
    "### Datasets \\& DataArrays\n",
    "\n",
    "Datasets and DataArrays are the fundamental labeled array containers in Xarray. We’ve read in a Dataset, which stores data variables as individual DataArrays. Look what happens if we pull out the \"tas\" variable that contains the surface air temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61772e-9034-424a-86d4-fb3a6ef74ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract with dictionary syntax\n",
    "ds[\"tas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e418d00-3162-454c-a298-bd545d1de513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract with dot notation\n",
    "ds.tas\n",
    "\n",
    "# Both methods return a DataArray object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a34187-5566-4b96-b84c-53a6c4e82a65",
   "metadata": {},
   "source": [
    "DataArrays contain dimensions, coordinates, and attributes, just like variables in a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7c930-764b-4f91-aab8-c3ac2210b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tas to a variable so we don't have to keep typing ds.tas\n",
    "tas = ds.tas\n",
    "\n",
    "# Print some metadata\n",
    "print(f\"DataArray name: {tas.name}\")\n",
    "print(f\"Named dimensions: {tas.dims}\")\n",
    "print(f\"Coordinates:\\n{tas.coords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa116a-66c3-42c6-b111-363eabd741c9",
   "metadata": {},
   "source": [
    "`dims` are our data axes, while `coords` are our labeled coordinate variables. This is an easy example because all of our coordinates are one-dimensional, but this won't always be the case!\n",
    "\n",
    "Let's also check out the attrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f72658-d9bf-4c80-9dd4-3c037ae7454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a674e2-e944-45a2-aaf5-2e030bb16bd0",
   "metadata": {},
   "source": [
    "We can extract the underlying data from a DataArray as an unlabeled NumPy array. This is useful sometimes when we need to perform operations that aren’t compatible with Xarray or we need to feed the data into another library.\n",
    "\n",
    "This might take a second because now we are **loading the data into memory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc587a-0f2d-4785-83a3-649875e84b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas.data # This is equivalent to tas.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4337d0-eed9-49c0-9bb1-a89f14f9c2d8",
   "metadata": {},
   "source": [
    "Let's check the data size and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd48e93-b9a3-4d68-9353-9d6e218d5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tas.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b58e9-37f8-4445-aebe-5f925522ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size, divide by 10**6 to make it MB\n",
    "tas.nbytes/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5ff08-2853-4448-9459-b11c6044e0af",
   "metadata": {},
   "source": [
    "That’s 228 MB — pretty big for a variable with just three dimensions. Can you imagine how big a file containing vertically varying air temperature (with 30+ levels) would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b9c92-5897-4b8e-93f5-6c91100c0241",
   "metadata": {},
   "source": [
    "### Xarray Comparison\n",
    "\n",
    "Xarray lets us manipulate and visualize data much more easily than using the more basic (but important!) libraries like NumPy or Scipy. Consider how we might visualize this data without Xarray.\n",
    "\n",
    "This is an example of how you should **not** do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6705ae-5e20-4c38-be73-f13e0fdb51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and coordinates to plot it\n",
    "# This approach requires manually handling data, slicing, and plotting — not ideal!\n",
    "lat_data = ds.lat.data\n",
    "lon_data = ds.lon.data\n",
    "tas_data = ds.tas.data\n",
    "\n",
    "# Take the time mean\n",
    "tas_mean = tas_data.mean(axis=0)\n",
    "\n",
    "# Now plot it\n",
    "plt.figure()\n",
    "plt.pcolormesh(lon_data,lat_data,tas_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a8313-37cc-42a0-a574-22db237f8d20",
   "metadata": {},
   "source": [
    "Xarray uses the names and coordinates of variables to perform similar operations and plotting, so it is much more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126aa173-faf7-4f2f-ae40-596d08af50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One line for the same plot\n",
    "tas.mean(dim=\"T\").plot(x=\"lon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ce2a0-9d9e-447f-9757-ce8e05c15147",
   "metadata": {},
   "source": [
    "Look, it even gave us axis labels and a colorbar! Of course we can override any of these properties to beautify the plot however we'd like, but this just shows how much more usable Xarray is. Here, we’re clearly taking the mean along the \"T\" (time) axis and plotting the result using longitude as the x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168cac2-e154-403b-92a0-718ed19d3b7f",
   "metadata": {},
   "source": [
    "### Slicing and dicing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b9fcd-38cf-4262-a856-b3671adcb6b0",
   "metadata": {},
   "source": [
    "#### Positional Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0415bcd-bd9b-483f-82b5-3a2112cf11d5",
   "metadata": {},
   "source": [
    "Xarray gives us several different ways to subset data, i.e., select which data we want to analyze or plot. The first is similar to how we subset NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9956d2-e4f9-4aae-ac80-32fbbcbe8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: tas is our DataArray holding the surface air temperature with dimensions of T, lat, and lon\n",
    "# Get the first time\n",
    "tas[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fad8d7-26cd-4783-8c5e-824de423d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or a range...\n",
    "tas[0:5,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af899e-f802-433b-a6e0-c2e01690d4f1",
   "metadata": {},
   "source": [
    "Remember: this isn't NumPy, this is **Xarray!** There has to be a better way to index.\n",
    "\n",
    "Xarray's main advantage is that the arrays are *labeled*. That means instead of memorizing the dimension/coordinate order, we can call them by name using `.isel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30755aed-80d7-4cba-8071-2e1fe98e5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first time\n",
    "tas.isel(T=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978285df-7fbf-4145-82ed-c16ae8f0cfea",
   "metadata": {},
   "source": [
    "We can also get a range, but it will look a bit different because we will use the `slice()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4c0be-8fbc-4c6d-9e6f-d2f027974d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first five times\n",
    "tas.isel(T=slice(0,5)) # Note: we can use None instead of 0 here for the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec52e2-bf55-48e9-84c6-4fa45587ad3a",
   "metadata": {},
   "source": [
    "This is great, but it requires us to have some prerequisite knowledge of the coordinates. Next, we will show how you can use the `.sel()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0336f-4f04-4cb3-81a8-13c8c964eb6e",
   "metadata": {},
   "source": [
    "#### Label-based indexing\n",
    "\n",
    "This is similar to how indexing works in Pandas. We can use `.sel()` to directly reference coordinate names and values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80686f31-2a46-441a-bb4d-d4028656c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data just for July of model-year 2016\n",
    "tas.sel(T=\"2016-07\") # Normally YYYY-MM(-DD) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616b46e-a473-4ce6-ab3b-ede143d6c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a range...\n",
    "# Get all data from January to December 2016\n",
    "tas.sel(T=slice(\"2016-01\",\"2016-12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb10e79-0541-41a4-91d7-b4afb54948c0",
   "metadata": {},
   "source": [
    "Notice how we use the Python built-in `slice()` function to specify our slice.\n",
    "\n",
    "But what if we don't know the *exact* position along a coordinate variable to index our data? Thankfully, Xarray allows us to perform nearest-neighbor sampling.\n",
    "\n",
    "Say we wanted the data for New York City, which is approximately 40.7°N and 74°W."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404aa85a-3839-48db-a61c-f338e924716a",
   "metadata": {},
   "source": [
    "#### Nearest-Neighbor Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3dbbc-66a8-46b4-bc4e-073ee4828877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the latitude and longitude of nyc\n",
    "nyc_lat, nyc_lon = 40.7, 360-74 # convert to degrees east\n",
    "\n",
    "tas_nyc = tas.sel(lat=nyc_lat,lon=nyc_lon,method=\"nearest\")\n",
    "tas_nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f7ad9-c09d-4377-8c5f-7b16870ddc9b",
   "metadata": {},
   "source": [
    "It's good practice to verify the results of using nearest-neighbor interpolation, but know that there is also a `tolerance` keyword argument if you want to make sure the result is close to what you wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95042594-e206-41a9-81b0-c3bfd7200cf2",
   "metadata": {},
   "source": [
    "#### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230a800-2aa8-4bbe-84dc-5556b3528bab",
   "metadata": {},
   "source": [
    "If nearest-neighbor sampling is not enough, we can even interpolate to the exact point of New York City. By default, it will use bilinear interpolation, but there are many other options that can be seen [here](https://docs.xarray.dev/en/stable/generated/xarray.DataArray.interp.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc6f523-f8ea-49f0-9c0d-f56cf756f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to NYC\n",
    "tas_nyc = tas.interp(lat=nyc_lat,lon=nyc_lon)\n",
    "tas_nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab125e8-e94d-4b19-adb5-434b739c221c",
   "metadata": {},
   "source": [
    "Just for fun, let's plot it. It's going to look messy because any signal is **masked by the noise of seasons**. We will address this in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ca6a3-3cdf-4e7f-a908-48548c6a850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_nyc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903615bd-6a9c-4857-b1ac-79cf7c2ce15a",
   "metadata": {},
   "source": [
    "### Computation with Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e8d66-6fa4-486b-bd2e-bb6e1eede6c7",
   "metadata": {},
   "source": [
    "#### Arithmetic & NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26704c7f-f48e-4a89-9682-041756c49411",
   "metadata": {},
   "source": [
    "For the most part, Xarray DataArrays and Datasets work intuitively with arithmetic and NumPy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0dcfd4-eff2-42f2-afda-00435d93aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperature from Kelvin to Fahrenheit\n",
    "tas_F = (tas - 273.15) * (9/5) + 32\n",
    "tas_F.mean(dim=\"T\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de9b5d-eb3f-4b05-aa2c-4fc9c893a20c",
   "metadata": {},
   "source": [
    "Let's take a step further and calculate the *saturation vapor pressure* from our data! We will use an approximation of the Clausius-Clapeyron relationship. You don't have to worry about how we got this equation, just how we implement it.\n",
    "\n",
    "$e_s(T) = 6.112 \\times exp(\\frac{17.67\\cdot T}{T + 243.5})$ where T is the temperature in °C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0d6f1-ad55-4400-b7be-6439fb8f864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to C\n",
    "tas_C = tas-273.15\n",
    "\n",
    "# compute saturation vapor pressure\n",
    "es = 6.112 * np.exp((17.67*tas_C)/(tas_C+243.5))\n",
    "es.rename(\"es\").mean(dim=\"T\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e61a0-e0ac-48ee-8ea2-3a9bc9f5fded",
   "metadata": {},
   "source": [
    "Even though we applied a NumPy function, the result remained a DataArray because Xarray preserves metadata during operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd1c9d-9fef-4bec-b598-066efccbef76",
   "metadata": {},
   "source": [
    "#### Broadcasting / Aligning\n",
    "\n",
    "Broadcasting refers to finding a common array shape when performing operations with arrays that have different shapes. Xarray is *excellent* at broadcasting and does so without much user input, although there are functions like `broadcast()` for explicit broadcasting.\n",
    "\n",
    "If we multiply the lat and the lon, Xarray automatically creates a new 2-dimensional DataArray with lat and lon dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf70737-984f-4e12-bba4-fe1b306a852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lat * ds.lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6b456-d341-499d-a101-4e10b0e1bd53",
   "metadata": {},
   "source": [
    "**Watch out: mismatched coordinates.** If two DataArrays share a dimension name but have slightly different coordinate values (e.g., due to floating-point differences or different grids), Xarray aligns them before operating — and points that don't match get dropped or filled with `NaN`. This is a common source of silent bugs in real research workflows. When results look unexpectedly empty or full of `NaN`, check whether your coordinates actually align."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7e0aa-d379-408d-a194-8425cc07a9cf",
   "metadata": {},
   "source": [
    "#### Groupby\n",
    "\n",
    "`groupby()` lets us bin data into groups and reduce. In other words, we can reorganize our data by sorting it into different categories. This is commonly done along the time axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f598566-4f91-426a-b606-4301355faa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby the season\n",
    "tas.groupby(\"T.season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab709e0-47a0-4f48-827f-bb006260b2c0",
   "metadata": {},
   "source": [
    "Notice that using `groupby()` just creates a DataArrayGroupBy object. The result isn’t directly usable yet, but notice how Xarray correctly identified meteorological seasons. We need to call another function to tell Xarray what to do with the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac1011-b6f9-475d-895a-5e1460a60d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the seasonal averages\n",
    "tas.groupby(\"T.season\").mean().plot(col=\"season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf01bc-fb10-4ee0-9026-afbbe9f2557d",
   "metadata": {},
   "source": [
    "#### Resample\n",
    "\n",
    "A similar function to `groupby()` is `resample()` which is a special `groupby` for time axes. With this function, we can very easily calculate annual averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ffe3c-1455-42cc-940c-5c9dc1d516dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the annual average temperature in NYC\n",
    "tas_nyc.resample(T=\"YE\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2113bae-6bad-470c-9a75-929bc35ede08",
   "metadata": {},
   "source": [
    "#### More Types of Plots\n",
    "\n",
    "Depending on the shape of the data, Xarray can make some pretty nice plots on its own. There are also plenty of keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750cd78a-7d12-44b6-81a5-a97bcb4f09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a line plot of the zonal-average seasonal temperature\n",
    "tas.groupby(\"T.season\").mean(dim=[\"lon\",\"T\"]).plot.line(hue=\"season\",y=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df249f20-59ca-4b3c-8f3b-bfd75d3aca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour North America's annual average temperatures\n",
    "tas.sel(lat=slice(20,50),lon=slice(220,300)).mean(dim=\"T\").plot.contour(levels=10,cmap=\"vanimo\",add_colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99366ef1-5a03-47e5-a88c-83c00ac88e88",
   "metadata": {},
   "source": [
    "### Reading and Writing Xarray Datasets/DataArrays\n",
    "\n",
    "Not all data you will encounter will be in a nice netCDF file pre-labeled for you, but that doesn't stop Xarray from being useful. Let's generate some data and create a DataArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589e0e9-e5a3-498d-8bb8-83c1fc0531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "data = 100 * np.random.randn(100,100)\n",
    "\n",
    "# Try casting it into a DataArray\n",
    "xr.DataArray(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e489f31-d01b-4681-97e0-7949265c0206",
   "metadata": {},
   "source": [
    "There are no dimension names, but we can fix that by providing them explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224732a-9b91-4b24-ae4d-7d279b088cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.DataArray(data,dims=[\"lat\",\"lon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c65d72-6bc1-420f-9fbc-55ab5e9abb4d",
   "metadata": {},
   "source": [
    "Next step, let's actually try adding coordinate variables. This will be make-believe latitude and longitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee002f-c8dd-467a-9983-f592194d3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create latitude and longitude numpy arrays\n",
    "lat = np.linspace(-90,90,100)\n",
    "lon = np.linspace(0,360,100)\n",
    "\n",
    "# Try making a DataArray now\n",
    "our_da = xr.DataArray(data,dims=[\"lat\",\"lon\"],coords=[lat,lon])\n",
    "our_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105be9e9-ca85-47be-9e11-b6a152b17a92",
   "metadata": {},
   "source": [
    "We can add useful attributes, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171db358-fd50-408f-945d-d9c65ad3b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_da.lat.attrs[\"units\"] = \"degree_north\"\n",
    "our_da.lon.attrs[\"units\"] = \"degree_east\"\n",
    "\n",
    "our_da.lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5695e7-6fbd-4ae9-bf74-58d5b5d913c5",
   "metadata": {},
   "source": [
    "What about a Dataset with multiple DataArrays? We can use `xr.merge()` to put DataArrays together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf10b5-fefb-488c-a5d2-403cf03da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new DataArray\n",
    "data2 = 100 * np.random.randn(100,100)\n",
    "our_other_da = xr.DataArray(data2,dims=[\"lat\",\"lon\"],coords=[lat,lon])\n",
    "\n",
    "# Name our DataArrays! Important!\n",
    "our_da = our_da.rename(\"dummy_var_1\")\n",
    "our_other_da = our_other_da.rename(\"dummy_var_2\")\n",
    "\n",
    "# Combine into one Dataset\n",
    "our_ds = xr.merge([our_da,our_other_da])\n",
    "our_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89379ba1-bb3e-42dd-9ca9-6ef41ed4bb39",
   "metadata": {},
   "source": [
    "What if we wanted to save or publish this data? We can easily save it as a netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992b55b-704f-4692-876f-19294e0aa668",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_ds.to_netcdf(\"dummy_netcdf.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb529a29-fa1b-42d5-a85d-b2408646bd57",
   "metadata": {},
   "source": [
    "### Xarray Exercise\n",
    "\n",
    "Let's look at the climatology of the surface air temperature in Brisbane, Australia. Produce a time series with month on the x-axis and surface air temperature in °C on the y-axis.\n",
    "\n",
    "1. Convert the temperature to °C and *fix the units attribute*.\n",
    "2. Select the point closest to Brisbane, Australia (27.5°S, 153.0°E).\n",
    "3. Using `groupby()`, create the monthly climatology of the surface air temperature.\n",
    "4. Plot it using Xarray's `plot()` function.\n",
    "\n",
    "*Hints:*\n",
    "- To convert K → °C, subtract 273.15: `tas_c = tas - 273.15`. Then update the units attribute: `tas_c.attrs[\"units\"] = \"°C\"`.\n",
    "- Brisbane is at **27.5°S** — southern latitudes are **negative** in this dataset. Longitude is 153.0°E.\n",
    "- `groupby(\"T.month\").mean(\"T\")` groups by month number (1–12) and averages over all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d69666-b3f4-464e-ad9c-5ad577080c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to C\n",
    "\n",
    "# Get data for Brisbane\n",
    "\n",
    "# Create monthly climatology\n",
    "\n",
    "# Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81e92c2f-172a-4889-9a30-f4b75dec957e",
   "metadata": {},
   "source": [
    "## Plotting Geospatial Data with Cartopy\n",
    "\n",
    "![image.png](https://scitools.org.uk/cartopy/docs/v0.16/_static/cartopy.png)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "We've already seen how we can create nice plots with Xarray alone. However, we need something more robust to put the data *on a map*, making sure that our data is being represented accurately on latitude/longitude grids.\n",
    "\n",
    "We will learn about two Python libraries for plotting data. The first library is **Cartopy** (Cartography Python), which is more widely used than the other library we will discuss, **PyGMT**. Each has their advantages and the choice of which to use is entirely up to you.\n",
    "\n",
    "Sources for this section:\n",
    "- [Ryan Abernathey's Cartopy Lecture](https://rabernat.github.io/research_computing_2018/maps-with-cartopy.html)\n",
    "- [Project Pythia Introduction to Cartopy Cookbook](https://foundations.projectpythia.org/core/cartopy/cartopy.html)\n",
    "- [Using Cartopy with Matplotlib](https://scitools.org.uk/cartopy/docs/latest/matplotlib/intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1403c42-193e-4ab8-9778-83b99a5cd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to start by importing Cartopy :)\n",
    "# Rarely do we have to import ALL of Cartopy, just some specific submodules\n",
    "\n",
    "import cartopy.crs as ccrs  # coordinate reference system\n",
    "import cartopy.feature as cfeature  # Cartoy's feature library (boundaries, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3210a0-dcdc-4e67-85c0-1d35fac28dad",
   "metadata": {},
   "source": [
    "Let's check out some of the projections available to us by typing `ccrs.` and hitting tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15602152-ab67-4724-a368-116d2d97d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccrs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f112d-8fc3-4b09-83a6-a41b6ea1fade",
   "metadata": {},
   "source": [
    "And look at one projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6121a6-03dd-4784-9139-7dbd59ed93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrs.PlateCarree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b237b-20b0-4410-8ab9-98a16cb10ac9",
   "metadata": {},
   "source": [
    "We can call it to see what the map looks like by default with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9bdcb-84e7-4d62-8087-a6560939b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c778a-6d21-4d17-8993-eac41a012e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrs.EckertIV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3183f-5379-431a-afb5-3957ee6a8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrs.NorthPolarStereo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c0492-d258-4609-a02f-87a81ebaf25d",
   "metadata": {},
   "source": [
    "### GeoAxes \n",
    "\n",
    "Cartopy’s main draw is how well it interacts with Matplotlib. If you remember from\n",
    "previous lectures, when you create a plot in Matplotlib, you produce an Axes (or AxesSubplot)\n",
    "object. Cartopy overrides this to produce an instance of its own axes class, called GeoAxes.\n",
    "Let’s start by making a matplotlib figure with some coastlines. Note that we will call the Matplotlib\n",
    "axes method with the “projection” argument. This tells Matplotlib we are going to be creating a Cartopy GeoAxes object. Let’s make a figure with the Mollweide projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a492276-d1b9-4c14-95c8-3ebd35319166",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # make a new figure\n",
    "ax = plt.axes(projection=ccrs.Mollweide()) # create a new GeoAxes instance\n",
    "ax.coastlines() # plot the coastlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98438b78-0a58-4af6-bd07-5912d2e12101",
   "metadata": {},
   "source": [
    "GeoAxes contains many helpful [functions](https://scitools.org.uk/cartopy/docs/latest/reference/generated/cartopy.mpl.geoaxes.GeoAxes.html), including many similar to the plotting functions of a Matplotlib Axes instance. We already used `coastlines()`, but let's try a few more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335005e-373a-4fe3-9868-1b9f79724504",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # make a new figure\n",
    "ax = plt.axes(projection=ccrs.Mollweide()) # create a new GeoAxes instance\n",
    "\n",
    "ax.coastlines() # plot the coastlines\n",
    "ax.stock_img() # Add a land/sea color background\n",
    "ax.gridlines() # Add gridlines\n",
    "\n",
    "# Specify the lat/lon box to display in the plot\n",
    "ax.set_extent([-10,45,35,70]) # Zoom in on Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05c9e8-8c2b-4d6c-a6c4-296995a34526",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "We imported `cfeature` before because it is the submodule that lets us access some Natural Earth datasets containing \"features\" like political boundaries. Let's add a few features to our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fd1d8-6988-4d66-a610-cd10de8db97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # make a new figure\n",
    "ax = plt.axes(projection=ccrs.Mollweide()) # create a new GeoAxes instance\n",
    "\n",
    "ax.coastlines() # plot the coastlines\n",
    "ax.stock_img() # Add a land/sea color background\n",
    "ax.gridlines() # Add gridlines\n",
    "\n",
    "# Specify the lat/lon box to display in the plot\n",
    "ax.set_extent([-10,45,35,70]) # Zoom in on Europe\n",
    "\n",
    "# Add political borders and rivers\n",
    "ax.add_feature(cfeature.RIVERS,edgecolor=\"blue\",linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2140879-a371-4ebb-8009-2fa84b1ebeed",
   "metadata": {},
   "source": [
    "By default, the borders and other features are pretty low-resolution. If we wanted to zoom on an individual country, we would probably want higher resolution features, which we can easily do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef983214-11f7-4087-b273-fd5924550c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get higher resolution features\n",
    "borders_50m = cfeature.NaturalEarthFeature(\"cultural\",\"admin_0_countries\",\"50m\",facecolor=\"none\")\n",
    "admin1_10m = cfeature.NaturalEarthFeature(\"cultural\",\"admin_1_states_provinces\",\"10m\",facecolor=\"none\",edgecolor=\"gray\",linewidth=0.3)\n",
    "rivers_10m = cfeature.NaturalEarthFeature(\"physical\",\"rivers_lake_centerlines\",\"10m\",edgecolor=\"deepskyblue\",facecolor=\"none\")\n",
    "ocean_50m = cfeature.NaturalEarthFeature(\"physical\",\"ocean\",\"50m\",edgecolor=\"none\",facecolor=cfeature.COLORS[\"water\"])\n",
    "land_50m = cfeature.NaturalEarthFeature(\"physical\",\"land\",\"50m\",edgecolor=\"none\",facecolor=cfeature.COLORS[\"land\"])\n",
    "\n",
    "fig = plt.figure() # make a new figure\n",
    "ax = plt.axes(projection=ccrs.Mollweide()) # create a new GeoAxes instance\n",
    "\n",
    "# Specify the lat/lon box to display in the plot\n",
    "ax.set_extent([6, 19, 36, 48]) # Zoom in on Europe\n",
    "\n",
    "# Iterate through list of features and add them to our map\n",
    "# Note: the order is IMPORTANT!\n",
    "for f in [land_50m,borders_50m,admin1_10m,rivers_10m,ocean_50m]:\n",
    "    ax.add_feature(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad2e22-d02a-4bb6-8e7c-2f85531501c3",
   "metadata": {},
   "source": [
    "### Combining Data & Cartopy\n",
    "\n",
    "#### Projection & Transform\n",
    "\n",
    "As we start to plot data on our Cartopy GeoAxes, there are two\n",
    "important keyword arguments to keep in mind: **projection** and **transform**.\n",
    "\n",
    "We've already had practice setting the projection of the GeoAxes object we create. However, if we\n",
    "want to plot data, *we need to give Cartopy more information about what our data looks like*. This\n",
    "is where the transform keyword argument comes in.\n",
    "\n",
    "Cartopy's documentation has a great [explanation](https://scitools.org.uk/cartopy/docs/latest/tutorials/understanding_transform.html). The core concept is that the projection of\n",
    "your axes is independent of the coordinate system your data is defined in. The projection argument\n",
    "is used when creating plots and determines the projection of the resulting plot (i.e. what the plot\n",
    "looks like). The transform argument to plotting functions tells Cartopy what coordinate system\n",
    "your data are defined in.\n",
    "\n",
    "Let's show this by plotting a line between two points. On a sphere, this can be done a few ways,\n",
    "including:\n",
    "- as the shortest straight line on the sphere (Geodetic)\n",
    "- as a straight line in projected (Cartesian) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea5ba5-16a5-4c18-bb15-430fc66a2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the lat and lons of our points\n",
    "# remember, degrees west and south are negatives\n",
    "# dictionaries should look familiar :)\n",
    "nyc = dict(lat=40.7128,lon=-74.0060)\n",
    "dubai = dict(lat=25.2048,lon=55.2708)\n",
    "\n",
    "# make a list of the lats and lons for plotting\n",
    "lats = [nyc['lat'],dubai['lat']]\n",
    "lons = [nyc['lon'],dubai['lon']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d922d5d-c804-4133-899d-41ef1eee59c7",
   "metadata": {},
   "source": [
    "Now we will plot the points and lines on a PlateCarree projection, once specifying the transform\n",
    "and once without. Note that if you do not specify the transform, Cartopy will assume the data is\n",
    "formatted the same as the underlying GeoAxes object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b13cf-73dc-4f7f-be3c-c1882a7fc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.plot(lons, lats, label='Equirectangular straight line')\n",
    "ax.plot(lons, lats, label='Great Circle', transform=ccrs.Geodetic())\n",
    "ax.coastlines()\n",
    "ax.legend()\n",
    "ax.set_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c07106-2856-49d5-84b8-10c8a762d804",
   "metadata": {},
   "source": [
    "As you can see, including the transform argument told Cartopy that our data is defined in the\n",
    "Geodetic coordinate system, and thus we plotted our great circle line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53177f-94bf-4539-948e-58e6d1903b8c",
   "metadata": {},
   "source": [
    "#### NumPy arrays with Cartopy\n",
    "\n",
    "We will make some fake data for now to show how plotting works with basic, unlabeled NumPy arrays. Later, we will combine our model data with Xarray and Cartopy to produce plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593aab0-a3ab-4add-a698-df63525c7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: the linspace function makes equidistant points\n",
    "lon = np.linspace(-80, 80, 25) # 80W to 80E\n",
    "lat = np.linspace(30, 70, 25) # 30N to 70N\n",
    "lon2d, lat2d = np.meshgrid(lon, lat) # makes 2D grid of lat/lon\n",
    "\n",
    "# make some random data\n",
    "data = np.cos(np.deg2rad(lat2d) * 4) + np.sin(np.deg2rad(lon2d) * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a6d80-85dd-4125-86a5-ebd6fd272d67",
   "metadata": {},
   "source": [
    "What happens when we plot it without the transform argument?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598bd3c-cea3-41da-a6ff-0a2153c5c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The projection keyword determines how the plot will look\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_global() # show the entire map\n",
    "ax.coastlines() # add coastlines\n",
    "ax.contourf(lon, lat, data) # didn't use transform, but looks ok..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ccd368-d7a4-426a-b357-8b07618d552a",
   "metadata": {},
   "source": [
    "This looks fine because we are plotting on a PlateCarree projection and our data is defined in the\n",
    "same coordinate system. Even if we include the transform argument, nothing should change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5faa2-3d1c-4fe9-9b4b-0e0468c45170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data are defined in lat/lon coordinate system, so PlateCarree()\n",
    "# is the appropriate choice:\n",
    "data_crs = ccrs.PlateCarree()\n",
    "\n",
    "# The projection keyword determines how the plot will look\n",
    "plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "ax.contourf(lon, lat, data, transform=data_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647def02-abf2-4769-a0f2-35b72dd58946",
   "metadata": {},
   "source": [
    "Issues arise when we exclude the transform argument and our data and projection are not on the\n",
    "same coordinate system. Look at what happens if we try plotting the data without transform on\n",
    "a different projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf379f-c575-4745-89a8-63a5d031dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot a rotated pole projection\n",
    "projection = ccrs.RotatedPole(pole_longitude=-177.5, pole_latitude=37.5)\n",
    "plt.figure()\n",
    "\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "ax.contourf(lon, lat, data) # didn't use transform, RIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e08a6d-3ea3-4571-b793-ed61849ad74c",
   "metadata": {},
   "source": [
    "That’s definitely not right. Cartopy is assuming our data is on the rotated pole coordinate system\n",
    "already, which is incorrect. Let’s fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645d19e-f889-499e-b0bb-438cb701f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rotated pole projection again...\n",
    "projection = ccrs.RotatedPole(pole_longitude=-177.5, pole_latitude=37.5)\n",
    "plt.figure()\n",
    "\n",
    "ax = plt.axes(projection=projection)\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "\n",
    "# ...but now using the transform argument\n",
    "ax.contourf(lon, lat, data, transform=data_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fe82c-dca6-46ad-a726-1e9bc1fb879e",
   "metadata": {},
   "source": [
    "Here’s our lesson: **Always remember to include the transform and projection arguments\n",
    "when plotting data with Cartopy!**\n",
    "\n",
    "#### Xarray & Cartopy\n",
    "\n",
    "You should already have your surface air temperature from earlier. Let's try plotting it on a map with Cartopy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c12697-c979-44d1-abbd-fc02c5bd888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=ccrs.Mollweide()) # let's go with Mollweide\n",
    "\n",
    "# pick some date to plot the temperature\n",
    "tas.sel(T=\"2020-06\").plot(ax=ax,\n",
    "    transform=ccrs.PlateCarree(), # Notice that we can specify the transformation here\n",
    "    cbar_kwargs={'shrink': 0.5}, # This is just to shrink the colorbar a bit\n",
    ")\n",
    "\n",
    "# spruce it up\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "# trim some whitespace\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820056f-d482-46d2-bb6c-fbf1d8d0878a",
   "metadata": {},
   "source": [
    "In just a few lines, we were able to create a publication-worthy plot. Cartopy and Xarray work well together.\n",
    "\n",
    "To save a figure to disk: `plt.savefig(\"filename.png\", dpi=300, bbox_inches=\"tight\")`. For PyGMT figures, use `fig.savefig(\"filename.png\")` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa89ad7-d12e-491f-a542-c03097adb1d5",
   "metadata": {},
   "source": [
    "##### Example: Plotting Surface Winds\n",
    "\n",
    "Let's do something a bit different. Let's try looking at the annual average 10 meter winds in CONUS in a CMIP6 experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d72e5f-faf3-41a0-bc05-8a1b902ac63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set URL\n",
    "url_uas = (\"http://mary.ldeo.columbia.edu:81/CMIP6i/.byScenario/.ssp585/.Amon/\"+\n",
    "           \".uas/.GFDL-CM4/.gr1/.r1i1p1f1/.uas/dods\") # URL to zonal-wind file\n",
    "url_vas = url_uas.replace(\"uas\",\"vas\") # Replace uas with vas for meridional-wind file\n",
    "\n",
    "# Read in the data while temporarily ignoring the time dimension\n",
    "ds_uas = fix_calendar(xr.open_dataset(url_uas, decode_times=False))\n",
    "ds_vas = fix_calendar(xr.open_dataset(url_vas, decode_times=False))\n",
    "\n",
    "# Combine uas and vas into one Dataset\n",
    "ds_winds = xr.merge([ds_uas,ds_vas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdd2de-1e38-4585-b414-20294543b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# Specify our projection\n",
    "proj = ccrs.AlbersEqualArea(central_longitude=-100, central_latitude=40)\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "ds_winds.mean(dim=\"T\").plot.quiver(x=\"lon\",y=\"lat\",u=\"uas\",v=\"vas\",transform=ccrs.PlateCarree(),ax=ax,scale=100,color=\"red\")\n",
    "\n",
    "ax.set_extent((-127,-63,20,50))\n",
    "\n",
    "# spruce up the plot, this time with states and borders\n",
    "ax.add_feature(cfeature.BORDERS)\n",
    "ax.add_feature(cfeature.STATES)\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580986f4-1108-40dc-a91e-ed172d8ad6cd",
   "metadata": {},
   "source": [
    "##### Exercise: Plotting Arctic Sea Ice\n",
    "\n",
    "Using the sic variable defined below, create a map of the sea ice concentration in March of\n",
    "1990\\*. Use an orthographic projection centered on the North Pole. Add coastlines, gridlines, and\n",
    "be sure to use an appropriate [colormap](https://matplotlib.org/stable/users/explain/colors/colormaps.html).\n",
    "\n",
    "\n",
    "\\* As a reminder, these historical model simulations do not correspond to the actual weather at the\n",
    "given date. You can think of it as March 1990 in some other timeline cooked up by the model.\n",
    "\n",
    "*Hints:*\n",
    "- `ccrs.Orthographic(central_longitude=0, central_latitude=90)` centers the view on the North Pole.\n",
    "- Select March 1990 with `.sel(time=\"1990-03\")`.\n",
    "- Sea ice concentration (`sic`) ranges from 0–100%. A sequential colormap like `\"Blues\"` or `\"YlOrRd_r\"` works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f026ce-eb6a-4150-b4dd-6a747a8cfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"http://esgf-node.ornl.gov/thredds/dodsC/cmip5_css02_data/cmip5/\"\n",
    "    \"output1/CCCma/CanESM2/historical/mon/seaIce/OImon/r1i1p1/sic/1/\"\n",
    "    \"sic_OImon_CanESM2_historical_r1i1p1_185001-200512.nc\"\n",
    ")\n",
    "LOCAL_SIC = \"sic_CanESM2_historical_r1i1p1_199003.nc\"\n",
    "\n",
    "try:\n",
    "    ds = xr.open_dataset(url)\n",
    "    print(\"Loaded from ESGF ORNL (full dataset: 1850–2005).\")\n",
    "except Exception as e:\n",
    "    print(f\"ESGF unavailable ({e})\\nLoading local fallback (March 1990 only).\")\n",
    "    ds = xr.open_dataset(LOCAL_SIC)\n",
    "\n",
    "ds.sic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240ffe0-c5f9-4bac-ae15-894579ca286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make figure with Orthographic projection\n",
    "\n",
    "# select and plot sic at correct date\n",
    "\n",
    "# add coastlines and gridlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdd99c-fabe-46be-a991-9be6793e1c76",
   "metadata": {},
   "source": [
    "##### Exercise: Plotting ENSO\n",
    "\n",
    "El Niño and La Niña events are some of the most impactful climate\n",
    "events on Earth. El Niños produce especially warm sea surface temperatures in the Eastern Pacific\n",
    "near Peru and central Pacific, while La Niña events produce anomalously cold sea surface temperatures.\n",
    "\n",
    "Using the dataset below, calculate the average sea surface temperature anomaly over the\n",
    "period from July 2007 to June 2008. Plot it on a Mollweide projection, centered on the Pacific,\n",
    "and set the extent to be from 95E to 55W and 60S to 70N. Don't forget coastlines. Based on your\n",
    "plot, was the 2007-2008 event an El Niño or La Niña?\n",
    "\n",
    "*Hint:* An **anomaly** is the departure from the long-term average. Here are the steps:\n",
    "1. Compute the monthly climatology (long-term average for each month) with `sst.groupby(\"time.month\").mean(dim=\"time\")`.\n",
    "2. Select the period of interest from `sst` using `.sel(time=slice(\"2007-07-01\", \"2008-06-01\"))`.\n",
    "3. Subtract the climatology from the selected period using `.groupby(\"time.month\") - monthly_clim`, then take the time mean with `.mean(dim=\"time\")`.\n",
    "4. To center the Mollweide projection on the Pacific, use `ccrs.Mollweide(central_longitude=-160)`.\n",
    "5. Don't forget to pass `transform=ccrs.PlateCarree()` when plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87dab4c-bc5c-4527-94e9-21f22d3ade8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = xr.open_dataset(\"https://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\").sst\n",
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb78c5-3035-4490-ab6d-1280f44f5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate anomaly\n",
    "\n",
    "# make figure and Mollweide projection\n",
    "\n",
    "# plot anomaly, set extent, add coastlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1eb34-4f05-4dcf-ba89-194f1da680d2",
   "metadata": {},
   "source": [
    "## Alternative Mapping Library: PyGMT\n",
    "\n",
    "<img src=\"https://forum.generic-mapping-tools.org/uploads/default/original/1X/3640d9ae84122cb7ffaaae64601b32777fa113de.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Sources:\n",
    "- [PyGMT Documentation](https://www.pygmt.org/dev/index.html)\n",
    "\n",
    "PyGMT is a Python library for making maps and figures using the Generic Mapping Tools, a widely used command-line program in the Earth Sciences. It is a solid alternative to Cartopy for map-making. Some advantages over Cartopy are:\n",
    "- Higher quality maps\n",
    "- More functions for plotting geophysical data\n",
    "- Full integration with Generic Mapping Tools for even more functions\n",
    "- **Does not use Matplotlib!**\n",
    "\n",
    "However, there are a few reasons why you might pick Cartopy over PyGMT:\n",
    "- PyGMT has a steeper learning curve, less Pythonic\n",
    "- Less flexible for general mapping purposes\n",
    "- Requires Generic Mapping Tools installed\n",
    "- Smaller user base\n",
    "\n",
    "TL;DR: PyGMT is more specialized for the Earth Sciences and tends to make better maps out-of-the-box, but its specialization comes at a cost of usability and generic application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f099fab-2ead-41a9-a0b0-0440a7ed3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing PyGMT\n",
    "import pygmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910ee01-3deb-41c0-875c-64021901fa35",
   "metadata": {},
   "source": [
    "### Shorelines\n",
    "\n",
    "Starting easy, let's just plot shorelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64129721-64c1-467a-aa84-529180ad81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "# region=\"g\"       → global extent (entire world)\n",
    "# projection=\"W15c\" → Winkel tripel projection, 15 cm wide\n",
    "# frame=True        → draw the map border\n",
    "fig.basemap(region=\"g\", projection=\"W15c\", frame=True)\n",
    "fig.coast(shorelines=True) # Draw shorelines\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a1208-bc7c-4b08-bb7b-cf90b8e57e2c",
   "metadata": {},
   "source": [
    "Remember, PyGMT does NOT use Matplotlib. It is its own Figure object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d67d-a4e6-4247-8634-070baae9093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a6336-aef3-4329-8570-4057d7079258",
   "metadata": {},
   "source": [
    "There are 4 levels of shorelines, ranging from coastlines to lakeshores, all the way down to lakes in islands in lakes! To only plot the coastlines, we are going to specify the shorelines argument in the `coast()` function with a \"1\" for only the highest level (coastlines) and the pen to draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb79654-89c7-4019-92ea-728df502354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "fig.basemap(region=\"g\", projection=\"W15c\", frame=True) # btw, frame=plot outline\n",
    "# Pen format for shorelines: \"level/width,color\" — 0.5p = 0.5 point width\n",
    "fig.coast(shorelines=\"1/0.5p,black\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1ddec-a2df-4abe-9b28-6a390f65e345",
   "metadata": {},
   "source": [
    "Let's finish off this section by adding colors for land and water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10e16c-2fe2-4b83-9bdd-aae4c426acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "fig.basemap(region=\"g\", projection=\"W15c\", frame=True)\n",
    "fig.coast(land=\"#666666\", water=\"skyblue\") # Specify colors now\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f3ba9-0751-4aa4-95af-1fba17b3e715",
   "metadata": {},
   "source": [
    "### Frames, Ticks, Titles, and Labels\n",
    "\n",
    "Previously, we set `frame = True`, but we can actually modify the frame on our plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc560a94-87be-49e3-94bf-fb1d215a83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "fig.coast(shorelines=\"1/0.5p\", region=[-180, 180, -60, 60], projection=\"M25c\") # Mercator\n",
    "fig.basemap(frame=\"f\") # f = default GMT frame\n",
    "fig.show(width=800) # Notice that figure width goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135816c-89b4-42b6-8b56-abd8e97cb034",
   "metadata": {},
   "source": [
    "To add ticklines like we did in our previous maps, we set `frame` to either `True` or `\"af\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f6542-6f9f-4910-adf7-11a8fe3a6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "fig.coast(shorelines=\"1/0.5p\", region=[-180, 180, -60, 60], projection=\"M25c\")\n",
    "fig.basemap(frame=\"af\")\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e339e9e-cfe6-439d-952b-9c083ee86f5c",
   "metadata": {},
   "source": [
    "We can add gridlines. It takes a bit of work to understand the syntax, but we can add gridlines by adding \"g\" to our `frame` argument. We can also specify the gridlines spacing (in degrees) by adding numbers after `a`, `f`, or `g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea1ab3-b44d-43c8-bba4-86af45605cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "fig.coast(shorelines=\"1/0.5p\", region=[-180, 180, -60, 60], projection=\"M25c\")\n",
    "fig.basemap(frame=\"a30f7.5g15\")\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0285466-be26-4881-8256-764666ade05b",
   "metadata": {},
   "source": [
    "We will end by showing how you can add a title to your plot. Titles get passed to the `frame` argument with a preceding `+t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876df405-3236-4f82-aeb9-562f33464e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pygmt.Figure()\n",
    "# region=\"TT\" specifies Trinidad and Tobago using the ISO country code\n",
    "fig.coast(shorelines=\"1/0.5p\", region=\"TT\", projection=\"M25c\")\n",
    "fig.basemap(frame=[\"a\", \"+tTrinidad and Tobago\"])\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb26a-b2a9-48fa-b251-5868e680a4b2",
   "metadata": {},
   "source": [
    "### Xarray & PyGMT\n",
    "\n",
    "In my opinion, Xarray and PyGMT do not work as nicely together as Xarray and Cartopy, but it's getting there. Let's try making a map of our surface air temperature data on a PyGMT map. We will rely on the `grdimage()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589539d-3ec4-45d9-9edb-e6908cd37051",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [275, 330, -60, 15]  # Set region to South America\n",
    "\n",
    "# CESM2's lat spacing (~0.94°) doesn't divide evenly into this region,\n",
    "# which causes a GMT warning. Interpolate to a regular 1° grid first —\n",
    "# this is the same .interp() we used earlier!\n",
    "tas_regrid = tas.mean(dim=\"T\").interp(\n",
    "    lat=np.arange(region[2], region[3] + 1, 1.0),\n",
    "    lon=np.arange(region[0], region[1] + 1, 1.0),\n",
    ")\n",
    "\n",
    "fig = pygmt.Figure()  # Create PyGMT Figure object\n",
    "\n",
    "# grdimage is PyGMT's equivalent of contourf/pcolormesh in Matplotlib\n",
    "fig.grdimage(\n",
    "    grid=tas_regrid,\n",
    "    region=region,\n",
    "    cmap=\"viridis\",\n",
    "    projection=\"W15c\",\n",
    "    frame=[\"af\", \"+tAnnual Average\"],  # Adds a title, too\n",
    ")\n",
    "\n",
    "# Add coastlines and borders with intermediate resolution\n",
    "fig.coast(shorelines=\"1/0.5p,black\", resolution=\"i\", borders=\"1/0.5p,black\")\n",
    "\n",
    "# Add a colorbar. x+l is our colorbar label, f+l is the units\n",
    "fig.colorbar(frame=['af+l\"K\"', \"x+lSurface Air Temperature\"])\n",
    "\n",
    "# Let's add a few cities on our map\n",
    "# Define cities\n",
    "cities = [\n",
    "    {\"name\": \"Bogotá\", \"lat\": 4.711, \"lon\": 285.928},\n",
    "    {\"name\": \"São Paulo\", \"lat\": -23.550, \"lon\": 313.367},\n",
    "    {\"name\": \"Buenos Aires\", \"lat\": -34.603, \"lon\": 301.619},\n",
    "    {\"name\": \"Lima\", \"lat\": -12.046, \"lon\": 282.958},\n",
    "    {\"name\": \"Santiago\", \"lat\": -33.448, \"lon\": 289.331},\n",
    "]\n",
    "\n",
    "# Plot each city\n",
    "for city in cities:\n",
    "    fig.plot(x=city[\"lon\"], y=city[\"lat\"], style=\"c0.25c\", pen=\"white\")\n",
    "    fig.text(\n",
    "        x=city[\"lon\"] + 1,\n",
    "        y=city[\"lat\"],\n",
    "        text=city[\"name\"],\n",
    "        font=\"10p,Helvetica-Bold,black\",\n",
    "        justify=\"LM\",\n",
    "    )\n",
    "\n",
    "fig.show(width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b619a-41a1-4c72-a567-b18c632fec56",
   "metadata": {},
   "source": [
    "##### Exercise: Sea level change with Xarray and PyGMT.\n",
    "\n",
    "Use the code below to read in a CMIP6 model's sea-level variable. Then, calculate the change in sea level between 2015 and 2100. Finally, plot it using PyGMT. Use the \"R15c\" projection and the \"vik\" colormap.\n",
    "\n",
    "*Hints:*\n",
    "- Select a year's data with `.sel(time=slice(\"2100-01\", \"2100-12\")).mean(\"time\")`, then subtract the 2015 equivalent.\n",
    "- `fig.grdimage(grid=..., region=\"d\", projection=\"R15c\", cmap=\"vik\", frame=True)` will plot the data. `\"d\"` means global domain; `\"R15c\"` is the Robinson projection.\n",
    "- Run `pygmt.makecpt(cmap=\"vik\", series=[vmin, vmax, step], symmetric=True)` before `grdimage` to set up the diverging colormap. Choose `vmin`/`vmax` based on the data range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06db08-f7f7-46c3-bb4c-11d93976af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "ds = xr.open_zarr(\n",
    "    \"gs://cmip6/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-ESM4/ssp585/r1i1p1f1/Omon/zos/gr/v20180701/\",\n",
    "    consolidated=True,\n",
    ")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c01822-7331-4a0b-bc97-c6ac190b7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sea-level change\n",
    "\n",
    "# Make PyGMT figure and plot it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b7058-943f-4619-9f9b-69ec87b9805a",
   "metadata": {},
   "source": [
    "## Extra: Get CMIP6 Data from Google Cloud Storage\n",
    "\n",
    "**This section is a bonus — we'll only cover it if time permits. Feel free to explore it on your own.**\n",
    "\n",
    "Source: [Project Pythia CMIP6 Cookbook](https://projectpythia.org/cmip6-cookbook/)\n",
    "\n",
    "So far, we have been accessing CMIP6 data stored on a server located at Lamont-Doherty Earth Observatory. OPeNDAP is great, but science is generally moving towards cloud-based data storage. Rather than purchasing a server with a fixed lifespan, upkeep costs, and unreliable hardware, universities can pay Google or Amazon to host the data for them. It is more reliable and efficient and still does not require us to have the data on our machines. Below, we look at how we can query and access such data.\n",
    "\n",
    "Let's start by just looking at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c7bc9-ea8c-4775-8bb6-59808128a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV will read the comma-separated value file on the cloud\n",
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "df.head() # prints the headers and a few lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff8180-5e9a-4a4b-8d24-e25414c087ef",
   "metadata": {},
   "source": [
    "We can use Pandas' `query()` function to find data matching what we'd like. Below, we look for data from the \"historical\" experiment, monthly atmospheric means (Amon), and downwelling shortwave radiation at the top of the atmosphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1bb81a-60ea-4b1c-80cc-a1e86da63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsdt = df.query(\n",
    "    \"activity_id=='CMIP' & table_id == 'Amon' & variable_id == 'rsdt' & experiment_id == 'historical'\"\n",
    ")\n",
    "df_rsdt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309c421-4901-4848-8d56-96acd0f955d6",
   "metadata": {},
   "source": [
    "We can further refine by finding experiments from NCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8f09d-0169-4500-b579-422068a33782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsdt_ncar = df_rsdt.query('institution_id == \"NCAR\"')\n",
    "df_rsdt_ncar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fccb79-165f-44a7-a960-321ffca184de",
   "metadata": {},
   "source": [
    "Let's try loading in the data, just the first one on the DataFrame above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27aa5d-e72f-4521-8691-4ba619616325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to a specific zarr store\n",
    "zstore = df_rsdt_ncar.zstore.values[-1]\n",
    "print(zstore)\n",
    "\n",
    "# open it using xarray and zarr\n",
    "ds = xr.open_zarr(zstore, consolidated=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d03e1-0aab-4663-9c9a-4daef2f2ab6f",
   "metadata": {},
   "source": [
    "And we can use the data exactly like how we were when we were accessing it from OPeNDAP. However, be careful! The dimensions and coordinate names are slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af4387-b378-4529-8d3d-4956e5a916d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.rsdt.groupby(\"time.season\").mean(dim=\"time\").plot(col=\"season\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "susc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
